# NE-Transformer

This is the implementation of paper at ****-2021.

## Download Pre-trained Embeddings
For char embedding, we use [Giga](https://pan.baidu.com/s/1pLO6T9D#list/path=%2F) and [BERT](https://blog.csdn.net/tailonh/article/details/105394010)(bert-base-chinese).

For word embedding, we use [Tencent embedding](https://ai.tencent.com/ailab/nlp/zh/embedding.html).
